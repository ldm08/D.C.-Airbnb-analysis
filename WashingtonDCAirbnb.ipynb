{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Motivation \n",
    "For this project, I was interested in using the Washington D.C. Airbnb data to better understand:\n",
    "### Properties & Pricing:\n",
    "1. How does pricing look across neighborhoods? Can I still find a relatively cheaper priced listing in one of the more expensive neighborhoods?\n",
    "2. How expensive are the top 5% of listings?\n",
    "3. Does proximity to attractions play a factor in price?\n",
    "4. Are there common property types, room types, bedroom and bathroom counts?\n",
    "### Hosts:\n",
    "5. Do hosts with multiple listings tend to be in certain neighborhoods?\n",
    "6. Do hosts with multiple listings stick to certain price points?\n",
    "7. Can we expect better reviews from hosts with businesses?\n",
    "### Reviews:\n",
    "8. Does sentiment in reviews tell us which neighborhoods or price ranges are better? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "import plotly\n",
    "%matplotlib inline\n",
    "\n",
    "# my favorite\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "\n",
    "# show full columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# cell width \n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## write fig for medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chart_studio\n",
    "import chart_studio.plotly as py\n",
    "import chart_studio.tools as tls\n",
    "\n",
    "username = 'lawrencedugom'\n",
    "api_key = 'o6hC0fxFQ8liKaqnDCbr'\n",
    "chart_studio.tools.set_credentials_file(username=username, api_key=api_key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "\n",
    "\n",
    "# where is orca \n",
    "plotly.io.orca.config.executable = '/Users/ldugom/anaconda3/envs/ds/bin/orca'\n",
    "\n",
    "def w_image(fig, name, width=1500, height=1000):\n",
    "    \n",
    "    # write html and png \n",
    "    #pio.write_html(fig, file=f\"{name}.html\", auto_open=True, width=width, height=height)\n",
    "    py.plot(fig, name, auto_open=False, width=width, height=height)\n",
    "    fig.write_image(f\"{name}.png\", width=width, height=height)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets available to us: listings, reviews, geographical information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listings data\n",
    "ls = pd.read_csv(\"data/listings.csv\")\n",
    "ls_d = pd.read_csv(\"data/listings 2.csv\")\n",
    "\n",
    "# reviews data\n",
    "rs = pd.read_csv(\"data/reviews.csv\")\n",
    "rs_d = pd.read_csv(\"data/reviews 2.csv\")\n",
    "\n",
    "\n",
    "# geography data\n",
    "geo = pd.read_csv(\"data/neighbourhoods.csv\")\n",
    "\n",
    "with open(\"data/neighbourhoods.geojson\") as jsonfile:\n",
    "    geojson = json.load(jsonfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary: Where are the neighbourhoods in DC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# set token\n",
    "px.set_mapbox_access_token(\"pk.eyJ1IjoibGF3cmVuY2VkIiwiYSI6ImNrODFzZnFnNzA0YmczZW9nNWN4aTFvdngifQ.VlB5-L7owXKEXo8JEePk7w\")\n",
    "fig = px.choropleth_mapbox(ls, geojson=geojson, title=\"Washington D.C. Neighbourhood Map\",\n",
    "                           locations=\"neighbourhood\", featureidkey=\"properties.neighbourhood\",opacity=0.5,\n",
    "                           mapbox_style=\"light\", zoom=11)\n",
    "\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore numerical attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melt listings data for graphing purposes \n",
    "melted_ls = pd.melt(ls,id_vars=['id', 'name', 'host_id', 'host_name', 'neighbourhood_group','neighbourhood', 'latitude', 'longitude'], value_vars=ls.select_dtypes(include=np.number).iloc[:, 5:].columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dropdown for attributes in melted dataframe\n",
    "dropdown_attribute = widgets.Dropdown(options = sorted(melted_ls.variable.unique()))\n",
    "\n",
    "# output\n",
    "output = widgets.Output()\n",
    "\n",
    "\n",
    "def view_attribute(attribute):\n",
    "    \n",
    "    # clear output for new attribute to be plotted \n",
    "    output.clear_output()\n",
    "    \n",
    "    # filter df to selected attribute\n",
    "    filtered = melted_ls[melted_ls['variable'] == attribute].copy()\n",
    "    \n",
    "    # filter out outliers \n",
    "    filtered = filtered[filtered.value.between(filtered.value.quantile(.10), filtered.value.quantile(.80))]\n",
    " \n",
    "    with output:\n",
    "        # set token\n",
    "        px.set_mapbox_access_token(\"pk.eyJ1IjoibGF3cmVuY2VkIiwiYSI6ImNrODFzZnFnNzA0YmczZW9nNWN4aTFvdngifQ.VlB5-L7owXKEXo8JEePk7w\")\n",
    "        fig = px.scatter_mapbox(filtered.rename({'value':'Listing Price'}, axis=1), lat=\"latitude\", lon=\"longitude\", color=\"Listing Price\", template=\"gridon\", \n",
    "                                color_continuous_scale=plotly.colors.diverging.RdYlGn,\n",
    "                                   opacity=0.4, center={\"lat\": 38.9072, \"lon\": -77.0369},\n",
    "                                   mapbox_style=\"light\", zoom=11)\n",
    "\n",
    "        fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "        fig.show()\n",
    "\n",
    "# change attribute\n",
    "def dropdown_attribute_handler(change):\n",
    "    view_attribute(change.new)\n",
    "    \n",
    "dropdown_attribute.observe(dropdown_attribute_handler, names=\"value\")\n",
    "display(dropdown_attribute)\n",
    "display(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  How does pricing look across neighborhoods? Can I still find a relatively cheaper priced listing in one of the more expensive neighborhoods?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that neighborhood averages range from $83 to $198 for the listings. Georgetown, Southwest, Spring Valley are the most expensive neighborhoods in the city. \n",
    "While remaining in the 10 most expensive neighborhoods, you can still save upwards of $50–100/night by choosing a less expensive neighborhood option. When comparing the top 12 neighborhoods in the list to the bottom 12 neighborhoods, you can save 2x your money by choosing an averaged priced item from the lower-priced tier of neighborhoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate outliers within neighbourhoods \n",
    "stdev = 3.0\n",
    "\n",
    "zscores = ls[['neighbourhood', 'price']].groupby('neighbourhood').transform(\n",
    "    lambda group: (group - group.mean()).div(group.std())).abs()\n",
    "\n",
    "outliers = zscores > stdev\n",
    "\n",
    "# take out outliers \n",
    "ls_nonoutliers = ls[~outliers.any(axis=1)].copy()\n",
    "\n",
    "\n",
    "# agg all the observations by nieghbourhood to get median and mean \n",
    "summary = ls.groupby(\"neighbourhood\").agg({'price':['mean', 'median', 'count']}).reset_index()\n",
    "summary.columns = ['Neighbourhood', 'Mean Price', 'Median Price', '# of listings']\n",
    "\n",
    "# strip outliers and redo agg\n",
    "summary_nonoutliers = ls_nonoutliers.groupby(\"neighbourhood\").agg({'price':['mean', 'count']}).reset_index()\n",
    "summary_nonoutliers.columns = ['Neighbourhood', 'Mean Price', '# of listings']\n",
    "\n",
    "# merge \n",
    "summary_final = pd.merge(summary, summary_nonoutliers, on='Neighbourhood', suffixes=[\" with outliers\", \" without outliers\"])\n",
    "summary_final[\"# of outliers\"] = summary_final[\"# of listings with outliers\"] - summary_final[\"# of listings without outliers\"] \n",
    "summary_final.drop(['# of listings without outliers'], axis=1, inplace=True)\n",
    "\n",
    "# mean price by nieghborhood \n",
    "(\n",
    "    summary_final\n",
    "    .sort_values([\"Mean Price without outliers\"], ascending=False)[['Neighbourhood', 'Mean Price with outliers', 'Mean Price without outliers', 'Median Price', '# of outliers']]\n",
    "    .style.background_gradient(cmap='RdYlGn', subset=['Mean Price with outliers', 'Median Price', 'Mean Price without outliers']) \n",
    "    \n",
    "          \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which neighborhoods have the widest variety of price ranges?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the averages across neighborhoods, it does look like one can find a relatively cheaper listing in a more expensive neighborhood. \n",
    "# In fact, nine of the top ten most expensive neighborhoods also have the biggest IQRs across all niehgborhoods, meaning that we can still find aparmtents less than\n",
    "# half of their averages in their neighborhoods (largest range of values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out top 5% to be fair\n",
    "ls_price_summary = ls.query(\"price <= price.quantile(.95)\")\n",
    "\n",
    "ls_price_summary = ls_price_summary.groupby(\"neighbourhood\")['price'].describe().reset_index()\n",
    "ls_price_summary['IQR'] = ls_price_summary['75%']  - ls_price_summary['25%']\n",
    "\n",
    "(\n",
    "ls_price_summary\n",
    "[[\"neighbourhood\", 'mean', 'std', '25%', '50%', '75%', 'IQR']].round(1)\n",
    ".sort_values([\"IQR\",\"mean\"], ascending=False).style.background_gradient(cmap=\"RdYlGn\")\n",
    "    .format(lambda x: \"${:.0f}\".format(x) if type(x) != str else x)\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_nonoutliers['price'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls[ls.price <= ls.price.quantile(.95)].price.hist(bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top and bottom twelve nieghborhoods\n",
    "most_expensive_neighbourhoods = summary_final.sort_values([\"Mean Price without outliers\"], ascending=False)[:10].Neighbourhood.values.tolist()\n",
    "cheapest_neighbourhoods= summary_final.sort_values([\"Mean Price without outliers\"])[:10].Neighbourhood.values.tolist()\n",
    "\n",
    "top = ls[ls.neighbourhood.isin(most_expensive_neighbourhoods + cheapest_neighbourhoods)]\n",
    "top['category'] = top['neighbourhood'].apply(lambda x: 'Top 10 Cheapest' if x in cheapest_neighbourhoods else 'Top 10 Most Expensive')\n",
    "\n",
    "\n",
    "# you save an average of 3x your money by choosing a nieghbourhood from the 5 cheapest rather than the 5 most expsensive \n",
    "top.groupby(\"category\").mean()['price'].reset_index().rename({'price':'Average price in Category'}, axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at the 10 most expensive and 10 most inexpensive neighbourhoods visually (39 total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.set_mapbox_access_token(\"pk.eyJ1IjoibGF3cmVuY2VkIiwiYSI6ImNrODFzZnFnNzA0YmczZW9nNWN4aTFvdngifQ.VlB5-L7owXKEXo8JEePk7w\")\n",
    "fig = px.scatter_mapbox(top, lat=\"latitude\", lon=\"longitude\", color=\"category\", template=\"simple_white\",center={\"lat\": 38.895, \"lon\": -77.024},\n",
    "                           mapbox_style=\"basic\", zoom=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average IQR\n",
    "ls_price_summary.IQR.mean()\n",
    "\n",
    "# median IQR\n",
    "ls_price_summary.IQR.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How expensive is the top 25%? \n",
    "### Answer: We can see that top listings start at  ~ \\\\$200, with a few going all the way to $10,000 ! Georgetown, Capitol, Hill and Downtown/Chinatown seem to pop out the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# clean price \n",
    "ls_d[\"price\"] = ls_d[\"price\"].str[1:].str.replace(\",\",\"\").astype(float)\n",
    "\n",
    "# detect outliers (169 total)\n",
    "outliers_df = ls_d[ls.price.between(ls_d.price.quantile(.75), ls_d.price.quantile(1))].copy().dropna(subset=[\"beds\"])\n",
    "\n",
    "sns.set_style(\"dark\") \n",
    "sns.set_palette(\"Set3\")\n",
    "\n",
    "fig = px.scatter(outliers_df, y=\"neighbourhood_cleansed\", x=\"price\", size=\"beds\", title=\"Top 25% of listings<br>sized by bedroom count\",\n",
    "                 color=\"beds\", template=\"plotly_dark\", color_continuous_scale=\"sunset\", width=1500, height=1000)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out figure \n",
    "py.plot(fig, \"top25%\", auto_open=False, width=1700, height=1250)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From a glance, it looks like the more expensive listings tend to be closer to downtown. Can wee assume the farther you move away from the center of DC, the more likely you are to find a cheaper listing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# bottom 95%\n",
    "ls_95 = ls.query(\"price <= price.quantile(.95)\").copy()\n",
    "lsd_95 = ls_d.query(\"price <= price.quantile(.95)\").copy()\n",
    "\n",
    "#create bins to eliminate outliers from dominating continuous scale\n",
    "ls_95['Price Decile'] = pd.qcut(ls_95['price'], 10)\n",
    "lsd_95['Price Decile'] = pd.qcut(lsd_95['price'], 10)\n",
    "\n",
    "\n",
    "# set token\n",
    "px.set_mapbox_access_token(\"pk.eyJ1IjoibGF3cmVuY2VkIiwiYSI6ImNrODFzZnFnNzA0YmczZW9nNWN4aTFvdngifQ.VlB5-L7owXKEXo8JEePk7w\")\n",
    "fig = px.scatter_mapbox(ls_95.sample(frac=.60), lat=\"latitude\", lon=\"longitude\", color=\"Price Decile\", template=\"simple_white\", opacity=0.5, \n",
    "                         color_discrete_sequence=px.colors.diverging.RdYlGn, category_orders={\"Price Decile\":sorted(ls_95['Price Decile'].unique().tolist())}, hover_data=[\"neighbourhood\", \"price\"],\n",
    "                           center={\"lat\": 38.895, \"lon\": -77.024},\n",
    "                           mapbox_style=\"basic\", zoom=10.5)\n",
    "\n",
    "\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "py.plot(fig, \"price deciles\", auto_open=False, width=1500, height=1200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image(\"binned_prices.png\", height=850, width=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To test our hypothesis about distance to downtown/attractions and being in more of an expensive price range, we'll calculate the distnace to Capital One Arena in Downtown DC as well as the Washington Monument, which is at teh center of a lot of the DC attractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monument = {'lat':38.8872036, 'lon':-77.045968}\n",
    "arena = {'lat':38.8980942,'lon':-77.0208438}\n",
    "center = {'lat':38.9072,'lon':-77.0369}\n",
    "wh = {'lat': 38.8977, 'lon':-77.0365}\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "\n",
    "# Thanks https://stackoverflow.com/questions/4913349/haversine-formula-in-python-bearing-and-distance-between-two-gps-points\n",
    "    \n",
    "    \n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    r = 3956 \n",
    "    return c * r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate each properties distance to washington monument and capital one arena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_d[\"distance_to_monument\"] = ls_d[['latitude', 'longitude']] \\\n",
    "    .apply(lambda row: haversine(row['latitude'], row['longitude'], monument.get(\"lat\"), monument.get(\"lon\")), axis=1)\n",
    "\n",
    "\n",
    "ls_d[\"distance_to_arena\"] = ls_d[['latitude', 'longitude']] \\\n",
    "    .apply(lambda row: haversine(row['latitude'], row['longitude'], arena.get(\"lat\"), arena.get(\"lon\")), axis=1)\n",
    "\n",
    "\n",
    "ls_d[\"distance_to_center\"] = ls_d[['latitude', 'longitude']] \\\n",
    "    .apply(lambda row: haversine(row['latitude'], row['longitude'], center.get(\"lat\"), center.get(\"lon\")), axis=1)\n",
    "\n",
    "\n",
    "ls_d[\"distance_to_whitehouse\"] = ls_d[['latitude', 'longitude']] \\\n",
    "    .apply(lambda row: haversine(row['latitude'], row['longitude'], wh.get(\"lat\"), wh.get(\"lon\")), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate correlations and price deciles\n",
    "distance_corrs = pd.concat([ls_d.select_dtypes(include=np.number), pd.get_dummies(ls_95['Price Decile'])], axis=1).corr()[[\"distance_to_monument\", \"distance_to_arena\", \"distance_to_center\", \"distance_to_whitehouse\"]].reset_index().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick curious check \n",
    "px.scatter(ls_d[ls_d.review_scores_location.notnull()], x=\"distance_to_monument\", y=\"review_scores_location\", trendline='lowess')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at correlations overall \n",
    "distance_corrs.round(3).sort_values(\"distance_to_whitehouse\").style.background_gradient(low=0.0, high=.10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer: slightly negative associaton for wh/monument distances, location review scores, host listing count. Weak postive correlation betweeen bedrooms, availability and lowest-priced decile of listings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: What kind of properties are these listings (property type, room type, bedroom count, bathroom count, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Property Types: 44% Apartments, 20% Houses, 15% Townhouses (3 form biggest share)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby prop type and then figure their share overall\n",
    "proptypes = (\n",
    "                ls_d.\n",
    "                    groupby(\"property_type\").count()[\"price\"]\n",
    "                    .reset_index().rename({'price':'# of listings'}, axis=1)\n",
    ")\n",
    "\n",
    "\n",
    "(\n",
    "    proptypes\n",
    "        .sort_values(\"# of listings\", ascending=False)\n",
    "        .assign(share=proptypes[\"# of listings\"]/ls_d.shape[0])\n",
    "        .style.background_gradient(cmap='Purples', subset=['share'])\n",
    "    \n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_summary = ls_d.groupby([\"neighbourhood_cleansed\", \"property_type\"])['id'].count().reset_index().rename({\"id\":\"listing count\"},axis=1).sort_values(\"listing count\",ascending=False)\n",
    "prop_fig = px.bar(prop_summary.sort_values(\"listing count\",ascending=False),\n",
    "       title=\"Property Type by Neighborhood\",x='neighbourhood_cleansed', y=\"listing count\", color=\"property_type\", \n",
    "                  template=\"plotly_dark\", height=900, color_discrete_sequence=plotly.colors.qualitative.Light24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_fig.update_xaxes(title='Neighborhood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "py.plot(prop_fig, \"property_types\", auto_open=False, width=1700, height=1250)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Room Types: We can see that the overwhelming majority of listings are entire homes/apartments ( 71%) , followed by private rooms (~25%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roomtypes = (\n",
    "                ls_d.\n",
    "                    groupby(\"room_type\").count()[\"price\"]\n",
    "                    .reset_index().rename({'price':'# of listings'}, axis=1)\n",
    ")\n",
    "\n",
    "\n",
    "(\n",
    "    roomtypes\n",
    "        .sort_values(\"# of listings\", ascending=False)\n",
    "        .assign(share=roomtypes[\"# of listings\"]/ls_d.shape[0])\n",
    "        .style.background_gradient(cmap='Blues', subset=['share'])\n",
    "    \n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set token\n",
    "px.set_mapbox_access_token(\"pk.eyJ1IjoibGF3cmVuY2VkIiwiYSI6ImNrODFzZnFnNzA0YmczZW9nNWN4aTFvdngifQ.VlB5-L7owXKEXo8JEePk7w\")\n",
    "fig = px.scatter_mapbox(ls_d.dropna(subset=['beds']), lat=\"latitude\", lon=\"longitude\", color=\"room_type\", template=\"simple_white\", size=\"beds\",\n",
    "                          hover_data=[\"neighbourhood\", \"price\"],\n",
    "                           center={\"lat\": 38.895, \"lon\": -77.024},\n",
    "                           mapbox_style=\"basic\", zoom=11.5)\n",
    "\n",
    "fig.update_layout(margin={\"r\":5,\"t\":0,\"l\":0,\"b\":0})\n",
    "py.plot(fig, \"room_types\", auto_open=False, width=1500, height=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary statistics for type of property types: mode of price, bathrooms, bedrooms and beds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prop_df = ls_d[['price', 'bathrooms','bedrooms','beds', 'property_type']].copy()\n",
    "prop_df = prop_df.groupby(\"property_type\").agg([('mode', lambda x: x.value_counts().index[0]),'count', 'mean']).reset_index()\n",
    "prop_df.columns = ['_'.join(col).strip() for col in prop_df.columns.values]\n",
    "prop_df.rename({'beds_count':'number_of_listings'}, axis=1, inplace=True)\n",
    "prop_df.drop([col for col in prop_df.columns if \"count\" in col], axis=1, inplace=True)\n",
    "prop_df.sort_values(\"number_of_listings\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 (Host Analysis):  Are there hosts that have multiple listings/have businesses using Aribnb? Do they individually tend to be in certain neighborhoods? Do they stick certain price points? Are their reviews impeccable due to their experience?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Are there hosts that have multiple listings/have businesses using Aribnb?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_subset = ls_d[['id', 'host_id','host_name', 'host_about', 'host_response_time','host_since', \n",
    "      'host_response_rate', 'host_acceptance_rate', 'host_is_superhost', 'host_listings_count', 'host_total_listings_count', 'neighbourhood',\n",
    "      'latitude', 'longitude', 'room_type', 'property_type', 'bathrooms', 'bedrooms', 'beds', 'price', 'minimum_nights', 'maximum_nights',\n",
    "      'availability_30', 'availability_60', 'availability_90','availability_365', 'number_of_reviews', 'number_of_reviews_ltm', \n",
    "      'review_scores_rating','review_scores_accuracy','review_scores_cleanliness','review_scores_checkin','review_scores_communication','review_scores_location','review_scores_value',\n",
    "      'reviews_per_month']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hosts that have more than one listing \n",
    "host_summary = (\n",
    "    ls_subset\n",
    "        .groupby([\"host_id\", \"host_name\"])\n",
    "        .count().reset_index()\n",
    "        .sort_values(\"id\", ascending=False)\n",
    "        .iloc[:,:3]\n",
    "        .rename({\"id\":\"# of listings\"}, axis=1)\n",
    "    )\n",
    "\n",
    "host_summary_multiple = host_summary[host_summary[\"# of listings\"] > 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer 1: 46% of the listings are owned by hosts with multiple listings. Thes guys are probably running businesses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(host_summary_multiple[\"# of listings\"]) / np.sum(host_summary[\"# of listings\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do these hosts have good scores and reviews? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_reviews = host_summary_multiple.merge(ls_subset, on = ['host_id', 'host_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# weight the scores of the hosts that have more than one listing by \"reviews per month\"\n",
    "host_grouped = (\n",
    "                host_reviews\n",
    "                    .dropna()\n",
    "                    .groupby(['host_id', 'host_name'])\n",
    "                    [['review_scores_rating','review_scores_accuracy','review_scores_cleanliness','review_scores_checkin','review_scores_communication','review_scores_location','review_scores_value',\n",
    "                          'reviews_per_month']]\n",
    ")\n",
    "\n",
    "(\n",
    "    # collect weighted averages \n",
    "    host_grouped\n",
    "        .apply(lambda x: pd.Series(np.average(x[['review_scores_rating','review_scores_accuracy',\n",
    "                                                 'review_scores_cleanliness','review_scores_checkin','review_scores_communication',\n",
    "                                                 'review_scores_location','review_scores_value']], weights=x[\"reviews_per_month\"], axis=0),\n",
    "                                   ['review_scores_rating','review_scores_accuracy','review_scores_cleanliness','review_scores_checkin',\n",
    "                                    'review_scores_communication','review_scores_location','review_scores_value']))\n",
    "    \n",
    "    # merge in helpful information \n",
    "    .merge(host_summary_multiple, on=['host_id', 'host_name'])\n",
    "    .sort_values(\"# of listings\", ascending=False)\n",
    "    .style.background_gradient(cmap='RdYlGn',subset=['review_scores_rating','review_scores_accuracy','review_scores_cleanliness','review_scores_checkin',\n",
    "                                    'review_scores_communication','review_scores_location','review_scores_value'])\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer 2: We do not see see too much fluctuation in the scores here, except for a couple bad apples with low accuracy scores as well. It generally looks like the review scores are generally postive for the top hosts and overall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_d[[col for col in ls_d.columns if \"review\" in col]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_d.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do they focus in one or two neighbourhoods? Focus on ceratin price points?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 100 hosts by # of listings \n",
    "top100hosts = host_summary[:100].host_id.values.tolist()\n",
    "\n",
    "# get mean price of listings acorss neighbourhoods for each host with multiple reviews\n",
    "prices_neighbourhoods = \\\n",
    "(\n",
    "    host_reviews[['id', 'host_name', 'host_id', 'price','neighbourhood']]\n",
    "    .groupby([\"host_name\",\"host_id\"])\n",
    "    .agg({'price':'mean', 'neighbourhood':lambda x:x.value_counts().index[0]}, axis=1)\n",
    "    .reset_index()\n",
    "    .rename({'price':'mean_price'}, axis=1)\n",
    ")\n",
    "\n",
    "multiples = prices_neighbourhoods.merge(host_summary[['host_id','# of listings']], on='host_id').sort_values(\"# of listings\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_summary_multiple.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asnwer 3 Part 1: It looks like out of the top 1078 hosts with multiple listings, 825 of them (~77%) are in only one neighourhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_summary = \\\n",
    "(\n",
    "    ls[ls.host_id.isin(host_summary_multiple.host_id.unique())]\n",
    "   .groupby([\"host_id\", \"neighbourhood\"])[\"id\"].agg([\"count\", \"sum\"]).reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(h_summary.host_id.value_counts().reset_index().query('host_id > 1')) / len(h_summary.host_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_neigh = h_summary.host_id.value_counts().reset_index().query('host_id > 1')['index'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(height=10, kind='bar',aspect=1.5,\n",
    "    data = h_summary.groupby(\"neighbourhood\")['count'].sum().reset_index().sort_values(\"count\", ascending=False)\n",
    "            .rename({'count':'Number of listings', 'neighbourhood':'Neighborhood' }, axis=1),\n",
    "    y='Neighborhood', x='Number of listings')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asnwer 3 Part 2: With the average IQR (of the middle 80%) of hosts with multiple listings being $40, it looks like these \"businesses\" tend to foucs on certain price points. There is no strong linear relationship between number of listings and IQR eitherm with the correlation around 8%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q3 = ls[ls.host_id.isin(multiples.host_id.unique())].groupby([\"host_id\"])[\"price\"].describe().reset_index()\n",
    "\n",
    "# filter out outliers\n",
    "q3_filtered = q3[q3[\"mean\"].between(q3[\"mean\"].quantile(.05), q3[\"mean\"].quantile(.95))]\n",
    "\n",
    "q3_filtered[\"IQR\"] = q3_filtered[\"75%\"] - q3_filtered[\"25%\"]\n",
    "                                                                                                                                                      \n",
    "q3_filtered.sort_values(\"count\", ascending=False).style.background_gradient(cmap=\"RdYlGn\", subset=[\"25%\", \"50%\", \"75%\", \"IQR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the mean \n",
    "q3_filtered[\"IQR\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# does IQR tend to go up with # of listings?\n",
    "q3_filtered[\"mean\"].corr(q3_filtered[\"IQR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iqr = px.scatter(q3_filtered.rename({\"mean\":\"Mean Price of listings\", \"50%\":\"50th percentile\"},axis=1), x=\"Mean Price of listings\", y='IQR', color='50th percentile', trendline='ols', \n",
    "                 template=\"ggplot2\", color_continuous_scale=plotly.colors.sequential.Darkmint,\n",
    "          title=\"<b>Mean Price vs IQR </b> (hosts with multiple listings)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iqr.update_yaxes(showgrid=False, tickformat='$')\n",
    "iqr.update_xaxes(showgrid=False, tickformat='$')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iqr.write_image(\"iqr.png\", width=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4 (Review Analysis): Even though reveiws are subjective, do ceratin neighbourhoods or price ranges reveal any patterns in review sentiment?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For this we'll use NLTK's Vader Sentiment Intensity Analyzer. Learn more here: https://medium.com/analytics-vidhya/simplifying-social-media-sentiment-analysis-using-vader-in-python-f9e6ec6fc52f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# 'normalized, weighted composite score'\n",
    "def get_sentiment(sentence):\n",
    "    \n",
    "    from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "    nltk_sentiment = SentimentIntensityAnalyzer()\n",
    "    score = nltk_sentiment.polarity_scores(sentence)\n",
    "    return score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a reviews datframe \n",
    "reviews = (\n",
    "            rs_d\n",
    "                .rename({'id':'review_id'}, axis=1)\n",
    "                .merge(ls[['host_id', 'host_name', 'id']], left_on='listing_id', right_on='id')\n",
    "                .drop(\"id\", axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attach sentiment scores\n",
    "reviews_final = pd.concat([reviews, reviews['comments'].astype(str).apply(get_sentiment).apply(pd.Series)], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze sentiment scores by host, by neighbourhood, by price range "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_scores = pd.read_csv(\"../../sentiment_scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_merged = vader_scores.merge(ls, left_on=['listing_id'], right_on=['id'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_summary = vader_merged[['listing_id', 'neighbourhood', 'date', 'neg', 'neu', 'pos', 'compound', 'price']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using vader's \"normalized\" score, it looks all neighboourhoods overall have good reviews, with the bottom 10ish neighbourhoods having relatively lower scores, but all in all, still above average (0-1) scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_groupby = vader_summary.groupby(\"neighbourhood\")[\"compound\"].describe().sort_values([\"50%\", \"count\"], ascending=False).reset_index()\n",
    "vader_groupby.style.background_gradient(cmap=\"RdYlGn\", subset=[\"25%\", \"50%\", \"75%\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# set token\n",
    "px.set_mapbox_access_token(\"pk.eyJ1IjoibGF3cmVuY2VkIiwiYSI6ImNrODFzZnFnNzA0YmczZW9nNWN4aTFvdngifQ.VlB5-L7owXKEXo8JEePk7w\")\n",
    "fig = px.choropleth_mapbox(vader_groupby, geojson=geojson, color=\"mean\", \n",
    "                               locations=\"neighbourhood\", featureidkey=\"properties.neighbourhood\",opacity=0.5, color_continuous_scale=px.colors.diverging.Geyser,\n",
    "                           center={\"lat\": 38.9072, \"lon\": -77.0369},\n",
    "                           mapbox_style=\"light\", zoom=10)\n",
    "\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py.plot(fig, \"mean_sentiment\", auto_open=False, width=1500, height=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# set token\n",
    "px.set_mapbox_access_token(\"pk.eyJ1IjoibGF3cmVuY2VkIiwiYSI6ImNrODFzZnFnNzA0YmczZW9nNWN4aTFvdngifQ.VlB5-L7owXKEXo8JEePk7w\")\n",
    "fig = px.choropleth_mapbox(vader_groupby, geojson=geojson, color=\"std\", \n",
    "                               locations=\"neighbourhood\", featureidkey=\"properties.neighbourhood\",opacity=0.5, color_continuous_scale=px.colors.diverging.Geyser,\n",
    "                           center={\"lat\": 38.9072, \"lon\": -77.0369},\n",
    "                           mapbox_style=\"light\", zoom=10)\n",
    "\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py.plot(fig, \"std_sentiment\", auto_open=False, width=1500, height=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does price range uncover patterns in reviews ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_merged.groupby(\"Price Decile\")[\"compound\"].describe().reset_index().sort_values(\"Price Decile\").style.background_gradient(cmap=\"RdYlGn\", subset=[\"mean\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer: Price range does not uncover too much besides the fact that the lowest two priced deciles have relatively lower scores.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
